{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d509d86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key=os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8305dd3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(profile={'max_input_tokens': 131072, 'max_output_tokens': 32768, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True}, client=<groq.resources.chat.completions.Completions object at 0x00000183AD991330>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000183AD991240>, model_name='llama-3.3-70b-versatile', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model=ChatGroq(model=\"llama-3.3-70b-versatile\",groq_api_key=groq_api_key)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a20b6a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Nice to meet you, Haaris. It's great to hear that you're an AI Engineer. That's a fascinating field, and I'm sure you're doing some exciting work. What specific areas of AI are you interested in or working on? Are you more focused on machine learning, natural language processing, computer vision, or something else?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 70, 'prompt_tokens': 48, 'total_tokens': 118, 'completion_time': 0.150793933, 'completion_tokens_details': None, 'prompt_time': 0.004201156, 'prompt_tokens_details': None, 'queue_time': 0.058690093, 'total_time': 0.154995089}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_68f543a7cc', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019ba951-b928-77b1-ad9b-081f8a159341-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 48, 'output_tokens': 70, 'total_tokens': 118})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "model.invoke([HumanMessage(content=\"Hi, My name is Haaris and I am an AI Engineer\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f2779c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Your name is Haaris, and you're an AI Engineer.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 138, 'total_tokens': 152, 'completion_time': 0.029863398, 'completion_tokens_details': None, 'prompt_time': 0.020659207, 'prompt_tokens_details': None, 'queue_time': 0.053732533, 'total_time': 0.050522605}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_dae98b5ecb', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019ba953-f0d0-7aa0-891d-550fbd6f0ee0-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 138, 'output_tokens': 14, 'total_tokens': 152})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi, My name is Haaris and I am an AI Engineer\"),\n",
    "        AIMessage(content=\"Nice to meet you, Haaris. It's great to hear that you're an AI Engineer. That's a fascinating field, and I'm sure you're doing some exciting work. What specific areas of AI are you interested in or working on? Are you more focused on machine learning, natural language processing, computer vision, or something else?\"),\n",
    "        HumanMessage(content=\"What is my naem and what do I do?\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801349e2",
   "metadata": {},
   "source": [
    "## Message History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1149d9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store={}\n",
    "\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id]=ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history=RunnableWithMessageHistory(model,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9181e7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cb7ee01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi, My name is Haaris and I am an AI Engineer\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0bfbc383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Haaris, welcome. It seems like we're starting fresh again. As an AI Engineer, you're part of a field that's constantly evolving and shaping the future of technology. What inspired you to become an AI Engineer, and what do you enjoy most about your work?\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3b6e73d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "config1={\"configurable\":{\"session_id\":\"chat2\"}}\n",
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my name?\")],\n",
    "    config=config1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "694682eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't know your name. I'm a large language model, I don't have any information about you, including your name. I'm here to help answer your questions and provide assistance, but I don't have any personal data about you. If you'd like to share your name, I'd be happy to chat with you!\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "439e2e5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Haaris.'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my name?\")],\n",
    "    config=config\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fca357",
   "metadata": {},
   "source": [
    "## Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4d8f4b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a helpful assistant. Answer all the question to best of your ability.\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain=prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c5da43eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Haaris, it's nice to meet you. Is there something I can help you with or would you like to chat?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 57, 'total_tokens': 84, 'completion_time': 0.043126725, 'completion_tokens_details': None, 'prompt_time': 0.002949455, 'prompt_tokens_details': None, 'queue_time': 0.053904905, 'total_time': 0.04607618}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_68f543a7cc', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019bac6b-4d66-7bd3-a656-12038d7e4b0c-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 57, 'output_tokens': 27, 'total_tokens': 84})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\":[HumanMessage(content=\"Hi my name is Haaris\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8e6d802d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history=RunnableWithMessageHistory(chain,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c49352d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello again Haaris, welcome back. I remember you introduced yourself earlier. What's on your mind today? Want to talk about something in particular or just say hello?\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat3\"}}\n",
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi my name is Haaris\")],\n",
    "    config=config\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "058120cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More complex\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are helpful assistant. Answer all questiojs to best of your ability in {language}.\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain=prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e4f66918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'नमस्ते हारिस, मैं आपका सहायक हूँ। मैं आपकी किस प्रकार से मदद कर सकता हूँ?'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=chain.invoke({\"messages\":[HumanMessage(content=\"Hi My name is Haaris.\")],\"language\":\"Hindi\"})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d9fae9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history=RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "35a02e13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'नमस्ते हारिस, मैं आपकी मदद करने में खुश हूँ। मैं आपके प्रश्नों का उत्तर देने की पूरी कोशिश करूँगा। क्या आप कुछ पूछना चाहते हैं या किसी विशेष विषय पर चर्चा करना चाहते हैं?'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat4\"}}\n",
    "response=with_message_history.invoke(\n",
    "    {'messages':[HumanMessage(content=\"Hi, I am Haaris\")],\"language\":\"Hindi\"},\n",
    "    config=config,\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "37fee991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'आपका नाम हारिस है! मुझे पहले ही पता है, हम पहले भी मिल चुके हैं!'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    {'messages':[HumanMessage(content=\"Hi, What is my name?\")],\"language\":\"Hindi\"},\n",
    "    config=config,\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578145c7",
   "metadata": {},
   "source": [
    "## Managing the Conversation History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "29f59515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\haari\\desktop\\genai\\llm_appwithlcem\\venv\\lib\\site-packages (4.57.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\haari\\desktop\\genai\\llm_appwithlcem\\venv\\lib\\site-packages (from transformers) (3.20.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\haari\\desktop\\genai\\llm_appwithlcem\\venv\\lib\\site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\haari\\desktop\\genai\\llm_appwithlcem\\venv\\lib\\site-packages (from transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\haari\\desktop\\genai\\llm_appwithlcem\\venv\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\haari\\desktop\\genai\\llm_appwithlcem\\venv\\lib\\site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\haari\\desktop\\genai\\llm_appwithlcem\\venv\\lib\\site-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in c:\\users\\haari\\desktop\\genai\\llm_appwithlcem\\venv\\lib\\site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\haari\\desktop\\genai\\llm_appwithlcem\\venv\\lib\\site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\haari\\desktop\\genai\\llm_appwithlcem\\venv\\lib\\site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\haari\\desktop\\genai\\llm_appwithlcem\\venv\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\haari\\desktop\\genai\\llm_appwithlcem\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2026.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\haari\\desktop\\genai\\llm_appwithlcem\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\haari\\desktop\\genai\\llm_appwithlcem\\venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\haari\\desktop\\genai\\llm_appwithlcem\\venv\\lib\\site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\haari\\desktop\\genai\\llm_appwithlcem\\venv\\lib\\site-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\haari\\desktop\\genai\\llm_appwithlcem\\venv\\lib\\site-packages (from requests->transformers) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\haari\\desktop\\genai\\llm_appwithlcem\\venv\\lib\\site-packages (from requests->transformers) (2026.1.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0201828a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"you're a good assistant\", additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage,trim_messages\n",
    "\n",
    "import tiktoken\n",
    "\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "def groq_token_counter(messages):\n",
    "    total = 0\n",
    "    for m in messages:\n",
    "        if m.content:\n",
    "            total += len(encoding.encode(m.content))\n",
    "    return total\n",
    "\n",
    "trimmer=trim_messages(\n",
    "    max_tokens=10,\n",
    "    strategy=\"last\",\n",
    "    token_counter=groq_token_counter,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\"\n",
    ")\n",
    "\n",
    "messages=[\n",
    "    SystemMessage(content=\"you're a good assistant\"),\n",
    "    HumanMessage(content=\"hi, I am Haaris\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I like Vanilla Icecream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"What is 2+2?\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "]\n",
    "\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b288aa42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Thank you for the kind words. I'll do my best to provide helpful and accurate responses to all your questions. Is there anything specific you'd like to know or discuss? I'm here to help.\""
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain=(\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\")|trimmer)\n",
    "    | prompt\n",
    "    | model\n",
    ")\n",
    "\n",
    "response=chain.invoke(\n",
    "    {\n",
    "        \"messages\":messages + [HumanMessage(content=\"Whay ice cream do I like?\")],\n",
    "        \"language\":\"English\"\n",
    "    }\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4afcdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "document="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
